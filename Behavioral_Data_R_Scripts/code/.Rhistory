show.se = T,
show.stat = T,
show.std = T)
# unpleasantness
tab_model(lm(traitEmpathyIRI_EC_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painUnpleasant, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(traitEmpathyIRI_PD_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painUnpleasant, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(traitEmpathyIRI_fant_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painUnpleasant, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(traitEmpathyIRI_PT_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painUnpleasant, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# fear
tab_model(lm(socialConnectedness_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_fear, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(loneliness_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_fear, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# pain rating
tab_model(lm(socialConnectedness_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painRating, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(loneliness_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painRating, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# unpleasantness
tab_model(lm(socialConnectedness_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painUnpleasant, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(loneliness_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painUnpleasant, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# fear
tab_model(lm(inclusionOtherSelf_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_fear, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(IOS_strangerNum_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_fear, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(IOS_studyPartner ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_fear, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# pain rating
tab_model(lm(inclusionOtherSelf_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painRating, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(IOS_strangerNum_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painRating, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(IOS_studyPartner ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painRating, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# unpleasantness of pain
tab_model(lm(inclusionOtherSelf_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painUnpleasant, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(IOS_strangerNum_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painUnpleasant, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
tab_model(lm(IOS_studyPartner ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painUnpleasant, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# fear
tab_model(lm(wellbeing_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_fear, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# pain rating
tab_model(lm(wellbeing_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painRating, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# unpleasantness of pain
tab_model(lm(wellbeing_mean_T2 ~ age + Male + Other + YesCollegeDegree + GroupID + stateEmp_painUnpleasant, data = dfS_noT3),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# List of variables to mean center for 3dMVM analysis in AFNI where these are our predictors of pattern similarity
variables_to_center <- c("loneliness_mean_T2", "traitEmpathyIRI_EC_mean_T2", "traitEmpathyIRI_PT_mean_T2", "stateEmp_fear", "stateEmp_painUnpleasant", "stateEmp_painRating"
)
# Loop over each variable to mean-center
for (var in variables_to_center) {
# Check if the column exists in dfS_noT3
if (var %in% colnames(dfS_noT3)) {
# Create the mean-centered column
dfS_noT3[[paste0("mc_", var)]] <- dfS_noT3[[var]] - mean(dfS_noT3[[var]], na.rm = TRUE)
} else {
warning(paste("Column", var, "is missing in dfS_noT3 and will be skipped."))
}
}
# Verify the result
head(dfS_noT3)
# Example of selecting and printing specific columns
mc_df = dfS_noT3 %>%
select(SubID, GroupID, mc_loneliness_mean_T2, mc_traitEmpathyIRI_EC_mean_T2,mc_traitEmpathyIRI_PT_mean_T2, mc_stateEmp_fear, mc_stateEmp_painUnpleasant, mc_stateEmp_painRating) %>%
print()
library(ggplot2)
library(ggthemes)  # For APA theme
library(ggExtra)
library(papaja)
# List of DVs and their corresponding IVs
dv_iv_mapping <- list(
"EC_patternsim_pain_dACC_MainEffect" = "mc_traitEmpathyIRI_EC_mean_T2",
"mc_stateEmp_fear_patternsim_anticipation_rightAI_Interaction" = "mc_stateEmp_fear",
"mc_stateEmp_painRating_patternsim_pain_leftAI_MainEffect" = "mc_stateEmp_painRating",
"mc_stateEmp_painUnpleasant_patternsim_anticipation_dACC_Interaction" = "mc_stateEmp_painUnpleasant"
)
# Function to generate custom labels for IVs, DVs, and title components
get_labels <- function(iv, dv) {
iv_labels <- list(
"mc_traitEmpathyIRI_EC_mean_T2" = "Empathic Concern",
"mc_loneliness_mean_T2" = "Loneliness",
"mc_stateEmp_fear" = "State Empathy (Fear)",
"mc_stateEmp_painUnpleasant" = "State Empathy (Unpleasantness)",
"mc_traitEmpathyIRI_PT_mean_T2" = "Perspective Taking",
"mc_stateEmp_painRating" = "State Empathy (Pain Rating)"
)
dv_labels <- c(
"decoding_anticipation" = "AUC (Fearful Anticipation)",
"decoding_pain" = "AUC (Pain)",
"patternsim_pain" = "Pattern Similarity (Pain)",
"patternsim_anticipation" = "Pattern Similarity (Fearful Anticipation)",
"self_pain" = "Brain Activity (Experience Pain)",
"self_anticipation" = "Brain Activity (Experience Fearful Anticipation)",
"other_pain" = "Brain Activity (Observe Pain)",
"other_anticipation" = "Brain Activity (Observe Fearful Anticipation)"
)
# Extract the DV type (e.g., "decoding_anticipation") and region (e.g., "dACC")
dv_type <- sub(".*_(decoding_anticipation|decoding_pain|patternsim_pain|patternsim_anticipation|self_pain|self_anticipation|other_pain|other_anticipation).*", "\\1", dv)
region <- ifelse(grepl("dACC", dv), "dACC",
ifelse(grepl("leftAI", dv), "Left AI", "Right AI"))
# Extract effect type (Main Effect, Interaction, or LKM vs PMR)
effect_type <- ifelse(grepl("MainEffect", dv), "Main Effect",
ifelse(grepl("Interaction", dv), "Interaction", "LKM vs PMR"))
iv_label <- iv_labels[[iv]]
dv_label <- paste(dv_labels[[dv_type]], region)
list(iv_label = iv_label, dv_label = dv_label, effect_type = effect_type)
}
# Loop through each DV-IV pair and create a plot
for (dv in names(dv_iv_mapping)) {
iv <- dv_iv_mapping[[dv]]
# Check if DV exists in dfS_noT3
if (dv %in% colnames(dfS_noT3) & iv %in% colnames(dfS_noT3)) {
labels <- get_labels(iv, dv)
# Create scatter plot with interaction
plot_interaction <- ggplot(dfS_noT3, aes_string(x = iv, y = dv, color = "GroupID")) +
geom_point() +
geom_smooth(method = "lm", aes(fill = "GroupID"), se = TRUE) +
scale_color_manual(values = c("LKM" = "darkblue", "PMR" = "steelblue1")) +
scale_fill_manual(values = c("LKM" = "darkblue", "PMR" = "steelblue1"), guide = FALSE) +
labs(
x = labels$iv_label,
y = labels$dv_label,
color = "Group",
title = paste(labels$effect_type)
) +
theme_apa()
# Add marginal density plots for each axis, with color by GroupID
plot_interaction <- ggMarginal(
plot_interaction,
type = "density",
groupFill = TRUE,  # Color densities by group
margins = "both",  # Add marginal plots on both axes
size = 5,  # Adjust marginal plot size
alpha = 0.4  # Transparency for density plots
)
# Print the plot
print(plot_interaction)
# Save the plot as a file
ggsave(
filename = paste0("/Users/md1864/Documents/GitHub/mind-and-life/Behavioral_Data_R_Scripts/data/plot_", dv, "_vs_", iv, ".png"),
plot = plot_interaction,
width = 8, height = 6
)
print(paste("Plot saved for DV:", dv, "and IV:", iv))
} else {
print(paste("Skipping DV:", dv, "or IV:", iv, "as it is not found in the dataframe."))
}
}
library(brms)
library(bayestestR)
# Factor recoding: mean-center GroupID to -0.5 and 0.5
dfB_all_long$GroupID <- factor(
dfB_all_long$GroupID,
levels = c("PMR", "LKM"),  # Original levels
labels = c(-0.5, 0.5)      # New levels
)
# Make time a factor with custom contrasts
dfB_all_long$time <- factor(dfB_all_long$time, levels = c(1, 2, 3))
contrasts(dfB_all_long$time) <- t(rbind(
c(-1, 1, 0),  # T1 vs T2
c(0, -1, 1)   # T2 vs T3
))
# Check
str(dfB_all_long)
contrasts(dfB_all_long$time)
# Example priors:
# - Normal(0,1) on all fixed effects (b) and the intercept
# - Exponential(1) as a weakly informative prior on all standard deviations (sd, sigma)
# These are just examples; adjust to suit your domain knowledge.
priors_ec <- c(
prior(normal(0, 1), class = "Intercept"),
prior(normal(0, 1), class = "b"),
prior(exponential(1), class = "sd"),
prior(exponential(1), class = "sigma")
)
# Fit the Bayesian model
fitH1e_bayes <- brm(
traitEmpathyIRI_EC_mean ~ 1 + time * GroupID + age + Male + Other + YesCollegeDegree +
(1 + time | SubID),      # Random effects structure
data       = dfB_all_long,
family     = gaussian(),
prior      = priors_ec,
iter       = 4000,         # Increase iterations for more stable estimation
warmup     = 2000,
chains     = 4,            # More chains = better exploration of posterior
cores      = 4,            # Use multiple cores if available
control    = list(adapt_delta = 0.95) # Helps for more complex models
)
x = 1 + 2
x
# chronological order of usage
library(gt) # advanced tables
library(dplyr) # %>%
library(janitor) # adorn_ns
library(kableExtra)  # apa table stuff
library(ggplot2) # ggplot
library(papaja) # theme_apa
library(gridExtra) # grid.arrange
library(moments) # skewness
library(openxlsx) # write.xlsx
library(reshape2) # cor table
library(nlme) # lme function
library(sjPlot) # tab_model
library(lmtest) #lrtest
# for T2 analysis, we use a wide df.
path <- "/Users/md1864/Documents/GitHub/mind-and-life/Behavioral_Data_R_Scripts/data" # CHANGE THIS PATH TO YOUR DIRECTORY!
dfB_noT3 <- read.csv(file.path(path, "clean/cleandata_fullSample_noT3.csv"), row.names = 1)
dfB_noT3_long <- read.csv(file.path(path, "clean/cleandata_fullSample_noT3_long.csv"), row.names = 1)
dfB_all_long <- read.csv(file.path(path, "clean/cleandata_fullSample_all_long.csv"), row.names = 1) # for analysis over time
# Ensure the group variable is a factor and PMR is the reference group (control)
dfB_noT3$GroupID <- as.factor(dfB_noT3$GroupID)
dfB_noT3$GroupID <- relevel(dfB_noT3$GroupID, ref = "PMR")
dfB_noT3_long$GroupID <- as.factor(dfB_noT3_long$GroupID)
dfB_noT3_long$GroupID <- relevel(dfB_noT3_long$GroupID, ref = "PMR")
dfB_all_long$GroupID <- as.factor(dfB_all_long$GroupID)
dfB_all_long$GroupID <- relevel(dfB_all_long$GroupID, ref = "PMR")
dfS_noT3 <- read.csv(file.path(path, "clean/cleandata_scanSample_noT3.csv"), row.names = 1)
dfS_noT3_long <- read.csv(file.path(path, "clean/cleandata_scanSample_noT3_long.csv"), row.names = 1)
dfS_noT3_all_long <- read.csv(file.path(path, "clean/cleandata_scanSample_all_long.csv"), row.names = 1)
# Ensure the group variable is a factor and PMR is the reference group (control)
dfS_noT3$GroupID <- as.factor(dfS_noT3$GroupID)
dfS_noT3$GroupID <- relevel(dfS_noT3$GroupID, ref = "PMR")
dfS_noT3_long$GroupID <- as.factor(dfS_noT3_long$GroupID)
dfS_noT3_long$GroupID <- relevel(dfS_noT3_long$GroupID, ref = "PMR")
dfS_noT3_all_long$GroupID <- as.factor(dfS_noT3_all_long$GroupID)
dfS_noT3_all_long$GroupID <- relevel(dfS_noT3_all_long$GroupID, ref = "PMR")
# Create the data frame
df_age <- as.data.frame(cbind(dfB_noT3$age, dfS_noT3$age))
colnames(df_age) <- c("dB1", "dB2")
# Calculate means and standard deviations
mean_dB1 <- mean(df_age$dB1)
mean_dB2 <- mean(df_age$dB2)
sd_dB1 <- sd(df_age$dB1)
sd_dB2 <- sd(df_age$dB2)
# Calculate the standard errors
se_dB1 <- sd_dB1 / sqrt(length(df_age$dB1))
se_dB2 <- sd_dB2 / sqrt(length(df_age$dB2))
# Calculate the 95% confidence intervals
alpha <- 0.05
t_critical <- qt(1 - alpha / 2, df = length(df_age$dB1) - 1)
ci_dB1_lower <- mean_dB1 - t_critical * se_dB1
ci_dB1_upper <- mean_dB1 + t_critical * se_dB1
ci_dB2_lower <- mean_dB2 - t_critical * se_dB2
ci_dB2_upper <- mean_dB2 + t_critical * se_dB2
# Perform the t-test
t_test <- t.test(df_age$dB1, df_age$dB2)
# Calculate Cohen's d and its confidence interval using compute.es
if (!require(compute.es)) {
install.packages("compute.es")
library(compute.es)
}
n1 <- length(df_age$dB1)
n2 <- length(df_age$dB2)
cohens_d <- (mean_dB1 - mean_dB2) / sqrt(((n1 - 1) * sd_dB1^2 + (n2 - 1) * sd_dB2^2) / (n1 + n2 - 2))
es <- tes(t_test$statistic, n1, n2, dig = 3)
# Print the results
cat("Mean of dB1:", mean_dB1, "\n")
cat("95% CI for mean of dB1:", ci_dB1_lower, "to", ci_dB1_upper, "\n")
cat("Mean of dB2:", mean_dB2, "\n")
cat("95% CI for mean of dB2:", ci_dB2_lower, "to", ci_dB2_upper, "\n")
print(t_test)
cat("Cohen's d:", cohens_d, "\n")
cat("95% CI for Cohen's d:", es$l.d, "to", es$u.d, "\n")
library(janitor) # adorn_ns
# Generating frequency table for age
age_table <- dfB_noT3 %>%
tabyl(agefull, GroupID) %>%
adorn_totals("row") %>% # Adds total counts per age
adorn_totals("col") %>% # Adds total counts per GroupID at the bottom
adorn_percentages("col") %>% # Converts counts to percentages by column (GroupID)
adorn_pct_formatting(digits = 1) %>%
adorn_ns(position = "front")
# Generating frequency table for Gender
gender_table <- dfB_noT3 %>%
tabyl(gender, GroupID) %>%
adorn_totals("row") %>% # Adds total counts per gender
adorn_totals("col") %>% # Adds total counts per GroupID at the bottom
adorn_percentages("col") %>% # Converts counts to percentages by column (GroupID)
adorn_pct_formatting(digits = 1) %>%
adorn_ns(position = "front")
# Generating frequency table for Ethnicity
ethnicity_table <- dfB_noT3 %>%
tabyl(ethnicity, GroupID) %>%
adorn_totals("row") %>% # Adds total counts per ethnicity
adorn_totals("col") %>% # Adds total counts per GroupID at the bottom
adorn_percentages("col") %>% # Converts counts to percentages by column (GroupID)
adorn_pct_formatting(digits = 1) %>%
adorn_ns(position = "front")
# Frequency table for Household Income by GroupID
income_table <- dfB_noT3 %>%
tabyl(income, GroupID) %>%
adorn_totals("row") %>% # Adds total counts per income
adorn_totals("col") %>% # Adds total counts per GroupID at the bottom
adorn_percentages("col") %>% # Converts counts to percentages by column (GroupID)
adorn_pct_formatting(digits = 1) %>%
adorn_ns(position = "front")
# Frequency table for Education by GroupID
education_table <- dfB_noT3 %>%
tabyl(education, GroupID) %>%
adorn_totals("row") %>% # Adds total counts per education
adorn_totals("col") %>% # Adds total counts per GroupID at the bottom
adorn_percentages("col") %>% # Converts counts to percentages by column (GroupID)
adorn_pct_formatting(digits = 1) %>%
adorn_ns(position = "front")
# Frequency table for Education by GroupID
employment_table <- dfB_noT3 %>%
tabyl(employment, GroupID) %>%
adorn_totals("row") %>% # Adds total counts per employment
adorn_totals("col") %>% # Adds total counts per GroupID at the bottom
adorn_percentages("col") %>% # Converts counts to percentages by column (GroupID)
adorn_pct_formatting(digits = 1) %>%
adorn_ns(position = "front")
# Frequency table for handedness by GroupID
handedness_table <- dfB_noT3 %>%
tabyl(handedness, GroupID) %>%
adorn_totals("row") %>% # Adds total counts per handedness
adorn_totals("col") %>% # Adds total counts per GroupID at the bottom
adorn_percentages("col") %>% # Converts counts to percentages by column (GroupID)
adorn_pct_formatting(digits = 1) %>%
adorn_ns(position = "front")
print(age_table)
print(gender_table)
print(ethnicity_table)
print(education_table)
print(employment_table)
print(income_table)
print(handedness_table)
# Run the model with the custom contrasts
fitH1e_1_contrast <- lme(traitEmpathyIRI_EC_mean ~ 1 + time*GroupID + age + Male + Other + YesCollegeDegree,
random = ~1 + time | SubID,
data = dfB_all_long,
method = "ML",
na.action = na.exclude)
tab_model(lme(traitEmpathyIRI_EC_mean ~ 1 + time*GroupID + age + Male + Other + YesCollegeDegree,
random = ~1 + time | SubID,
data = dfB_all_long,
method = "ML",
na.action = na.exclude),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# save model
tab_model(fitH1e_1_contrast, file = "fit1H1e_T3.html",
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# Run the model with the custom contrasts
fitH1g_1_contrast <- lme(traitEmpathyIRI_PT_mean ~ 1 + time*GroupID + age + Male + Other + YesCollegeDegree,
random = ~1 + time | SubID,
data = dfB_all_long,
method = "ML",
na.action = na.exclude)
tab_model(lme(traitEmpathyIRI_PT_mean ~ 1 + time*GroupID + age + Male + Other + YesCollegeDegree,
random = ~1 + time | SubID,
data = dfB_all_long,
method = "ML",
na.action = na.exclude),
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
# save model
tab_model(fitH1g_1_contrast, file = "fit1H1g_T3.html",
show.df = T,
show.aic = T,
show.se = T,
show.stat = T,
show.std = T)
library(brms)
library(bayestestR)
# Factor recoding: mean-center GroupID to -0.5 and 0.5
dfB_all_long$GroupID <- factor(
dfB_all_long$GroupID,
levels = c("PMR", "LKM"),  # Original levels
labels = c(-0.5, 0.5)      # New levels
)
# Make time a factor with custom contrasts
dfB_all_long$time <- factor(dfB_all_long$time, levels = c(1, 2, 3))
contrasts(dfB_all_long$time) <- t(rbind(
c(-1, 1, 0),  # T1 vs T2
c(0, -1, 1)   # T2 vs T3
))
# Check
str(dfB_all_long)
contrasts(dfB_all_long$time)
# Example priors:
# - Normal(0,1) on all fixed effects (b) and the intercept
# - Exponential(1) as a weakly informative prior on all standard deviations (sd, sigma)
# These are just examples; adjust to suit your domain knowledge.
priors_ec <- c(
prior(normal(0, 1), class = "Intercept"),
prior(normal(0, 1), class = "b"),
prior(exponential(1), class = "sd"),
prior(exponential(1), class = "sigma")
)
# Fit the Bayesian model
fitH1e_bayes <- brm(
traitEmpathyIRI_EC_mean ~ 1 + time * GroupID + age + Male + Other + YesCollegeDegree +
(1 + time | SubID),      # Random effects structure
data       = dfB_all_long,
family     = gaussian(),
prior      = priors_ec,
iter       = 4000,         # Increase iterations for more stable estimation
warmup     = 2000,
chains     = 4,            # More chains = better exploration of posterior
cores      = 4,            # Use multiple cores if available
control    = list(adapt_delta = 0.95) # Helps for more complex models
)
